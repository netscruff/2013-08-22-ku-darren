{
 "metadata": {
  "name": "02-BeautfulSoup-II-FULL"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since we will need to parse multiple urls for results we should put the code we run repeatedly into a Python function definition"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib, urllib2\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def page_results(soup):\n",
      "    \"\"\"Return a list of names\n",
      "    \n",
      "    Given an instance of BeautifulSoup, will return all the names it can find\n",
      "    in the search result table\n",
      "\n",
      "    \"\"\"\n",
      "    result_table = soup.find('table', class_='commonTable')\n",
      "    if result_table:\n",
      "        scientific_names = [italic.text for italic in result_table.find_all('i')]\n",
      "        return scientific_names\n",
      "    else:\n",
      "        return ['No results.']\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to rewrite the rest of the script to use the function and make sure we get the results from the additional pages until there are no more"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The FishBase search url\n",
      "result_url = 'http://fishbase.se/ComNames/CommonNameSearchList.php'\n",
      "# The common name we are serching on\n",
      "common_name = 'Tuna'\n",
      "scientific_names = []\n",
      "query_string = '?CommonName=' + common_name\n",
      "# Keep checking for the next link, when it no longer appers in the results we have\n",
      "# them all\n",
      "while True:\n",
      "    # Concatenate parts of the url together and have open the url\n",
      "    soup = BeautifulSoup(urllib2.urlopen(result_url + query_string))\n",
      "    scientific_names += page_results(soup)\n",
      "    # If there is an <a href=''>Next</a> tag in the results it means we don't have all\n",
      "    # the results and we should also parse additional results from the next page\n",
      "    next_link = soup.find('a', text='Next')\n",
      "    if next_link:\n",
      "        query_string = next_link['href']\n",
      "    else:\n",
      "        break\n",
      "for name in scientific_names:\n",
      "\tprint name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}